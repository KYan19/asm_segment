{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "78fedd9e-e6ed-49b7-930c-0711b362f267",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import multiprocessing as mp\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchgeo.datasets import NonGeoDataset, stack_samples, unbind_samples\n",
    "from torchgeo.datamodules import NonGeoDataModule\n",
    "from torchgeo.trainers import PixelwiseRegressionTask, SemanticSegmentationTask\n",
    "from torchvision.transforms.functional import pad\n",
    "from lightning.pytorch import Trainer\n",
    "from lightning.pytorch.callbacks import Callback, ModelCheckpoint\n",
    "from lightning.pytorch.loggers import WandbLogger\n",
    "import geopandas as gpd\n",
    "import rasterio\n",
    "import numpy as np\n",
    "import wandb\n",
    "\n",
    "sys.path.append(\"/n/home07/kayan/asm/scripts/\")\n",
    "from asm_datamodules import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "272dfbec-a734-4dba-9d5c-5c95a635da0c",
   "metadata": {},
   "source": [
    "## Set parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ba89244c-71d2-4270-82ce-5284cefa5032",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on 1 cuda(s) with 32 cpus\n"
     ]
    }
   ],
   "source": [
    "# device configuration\n",
    "device, num_devices = (\"cuda\", torch.cuda.device_count()) if torch.cuda.is_available() else (\"cpu\", mp.cpu_count())\n",
    "workers = mp.cpu_count()\n",
    "print(f\"Running on {num_devices} {device}(s) with {workers} cpus\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8317a999-a080-4094-a0f7-3077293a92b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model parameters\n",
    "lr = 1e-3\n",
    "n_epoch = 5\n",
    "batch_size = 8\n",
    "loss = \"ce\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a4d6414b-c0ae-4f9d-aff1-dfaaf35aecc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# file names and paths\n",
    "root = \"/n/home07/kayan/asm/data/\" # root for data files\n",
    "project = \"ASM_seg_test\" # project name in WandB\n",
    "run_name = \"0_losses+images\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83cbe694-f07d-49c6-8a9c-fcd3b641476a",
   "metadata": {},
   "source": [
    "## Create datamodule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bfb492e4-25b6-47fd-a18d-fd89b5a15a8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split with 64 train images, 16 validation images, and 20 test images\n",
      "Mine proportions\n",
      " Train: 1.0\n",
      " Validation: 1.0\n",
      " Test: 1.0\n"
     ]
    }
   ],
   "source": [
    "datamodule = ASMDataModule(batch_size=batch_size, num_workers=1, split=True, split_n=100, root=root, transforms=min_max_transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e27d9b13-4d78-47ab-9f45-c2d37aeae5d8",
   "metadata": {},
   "source": [
    "## Create prediction task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fb1d2ff9-e23a-4538-989f-55652c24220e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MySemanticSegmentationTask(SemanticSegmentationTask):\n",
    "    def validation_step(\n",
    "        self, batch, batch_idx, dataloader_idx=0\n",
    "    ) -> None:\n",
    "        \"\"\"Compute the validation loss and additional metrics.\n",
    "\n",
    "        Args:\n",
    "            batch: The output of your DataLoader.\n",
    "            batch_idx: Integer displaying index of this batch.\n",
    "            dataloader_idx: Index of the current dataloader.\n",
    "        \"\"\"\n",
    "        x = batch[\"image\"]\n",
    "        y = batch[\"mask\"]\n",
    "        y_hat = self(x)\n",
    "        y_hat_hard = y_hat.argmax(dim=1)\n",
    "        loss = self.criterion(y_hat, y)\n",
    "        self.log(\"val_loss\", loss)\n",
    "        self.val_metrics(y_hat_hard, y)\n",
    "        self.log_dict(self.val_metrics)\n",
    "\n",
    "        if (\n",
    "            batch_idx < 10\n",
    "            and hasattr(self.trainer, \"datamodule\")\n",
    "            and hasattr(self.trainer.datamodule, \"plot\")\n",
    "            and self.logger\n",
    "            and hasattr(self.logger, \"experiment\")\n",
    "            and hasattr(self.logger.experiment, \"add_figure\")\n",
    "        ):\n",
    "            try:\n",
    "                datamodule = self.trainer.datamodule\n",
    "                batch[\"prediction\"] = y_hat_hard\n",
    "                for key in [\"image\", \"mask\", \"prediction\"]:\n",
    "                    batch[key] = batch[key].cpu()\n",
    "                sample = unbind_samples(batch)[0]\n",
    "                fig = datamodule.plot(sample)\n",
    "                if fig:\n",
    "                    summary_writer = self.logger.experiment\n",
    "                    summary_writer.add_figure(\n",
    "                        f\"image/{batch_idx}\", fig, global_step=self.global_step\n",
    "                    )\n",
    "                    plt.close()\n",
    "            except ValueError:\n",
    "                pass\n",
    "        return y_hat_hard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "775168f2-a3c6-4846-a8ca-ca0b07f5c3c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "task = MySemanticSegmentationTask(\n",
    "    model=\"unet\",\n",
    "    backbone=\"resnet18\",\n",
    "    weights=True,\n",
    "    loss=loss,\n",
    "    in_channels=4,\n",
    "    num_classes=2,\n",
    "    lr=lr,\n",
    "    patience=5,\n",
    "    freeze_backbone=True,\n",
    "    freeze_decoder=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e68ca948-3561-4088-bf44-f62af1fd6f9a",
   "metadata": {},
   "source": [
    "## Set up WandB Logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "805ccc4c-b905-4d4c-b7e9-309c5968aa66",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb_logger = WandbLogger(project=project, name=run_name, log_model=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "0243de53-6382-42eb-b34b-ab9b3c080058",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WandBCallback(Callback):\n",
    "    def on_train_epoch_end(self, trainer, pl_module):\n",
    "        # log train loss to WandB\n",
    "        train_loss = trainer.callback_metrics.get(\"train_loss_epoch\")\n",
    "        if train_loss is not None:\n",
    "            wandb.log({\"train_loss\": train_loss.item()}, step=trainer.global_step)\n",
    "            \n",
    "    def on_validation_epoch_end(self, trainer, pl_module):\n",
    "        # Log validation loss to WandB\n",
    "        val_loss = trainer.callback_metrics.get(\"val_loss_epoch\")\n",
    "        if val_loss is not None:\n",
    "            wandb.log({\"val_loss\": val_loss.item()}, step=trainer.global_step)\n",
    "            \n",
    "    def on_validation_batch_end(self, trainer, pl_module, outputs, batch, batch_idx):\n",
    " \n",
    "        # outputs corresponds to our model predictions\n",
    "        # log n sample image predictions from first batch\n",
    "        if batch_idx == 0:\n",
    "            n = 5\n",
    "            imgs = batch[\"image\"]\n",
    "            masks = batch[\"mask\"].to(torch.float64)\n",
    "            outputs = outputs.to(torch.float64)\n",
    "            captions = [\"Image\", \"Ground truth\", \"Prediction\"]\n",
    "            for i in range(n):\n",
    "                wandb_logger.log_image(key=str(i), images=[imgs[i], masks[i], outputs[i]], caption=captions)\n",
    "            \n",
    "            '''wandb_logger.log_image(key='Images', images = [img for img in imgs[:n]])\n",
    "            wandb_logger.log_image(key='Ground truth', images = [mask for mask in masks[:n]])\n",
    "            wandb_logger.log_image(key='Prediction', images = [pred for pred in outputs[:n]])'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "755fad37-091e-46ad-84f8-5ccdcfa3178c",
   "metadata": {},
   "source": [
    "# Set up trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "00c4149c-dfc1-4833-b9bd-f9f43864773a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/n/home07/kayan/miniconda3/envs/geo-ml/lib/python3.11/site-packages/lightning/fabric/plugins/environments/slurm.py:191: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /n/home07/kayan/miniconda3/envs/geo-ml/lib/python3.1 ...\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "        accelerator=device,\n",
    "        devices=num_devices,\n",
    "        max_epochs=n_epoch,\n",
    "        callbacks=[WandBCallback()],\n",
    "        logger=wandb_logger\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c3503e0-1195-40a6-98a7-ca7311de3fc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/n/home07/kayan/miniconda3/envs/geo-ml/lib/python3.11/site-packages/lightning/pytorch/loggers/wandb.py:389: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.\n",
      "/n/home07/kayan/miniconda3/envs/geo-ml/lib/python3.11/site-packages/lightning/pytorch/callbacks/model_checkpoint.py:639: Checkpoint directory ./ASM_seg_test/2qk3vnv6/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name          | Type             | Params\n",
      "---------------------------------------------------\n",
      "0 | criterion     | CrossEntropyLoss | 0     \n",
      "1 | train_metrics | MetricCollection | 0     \n",
      "2 | val_metrics   | MetricCollection | 0     \n",
      "3 | test_metrics  | MetricCollection | 0     \n",
      "4 | model         | Unet             | 14.3 M\n",
      "---------------------------------------------------\n",
      "3.2 M     Trainable params\n",
      "11.2 M    Non-trainable params\n",
      "14.3 M    Total params\n",
      "57.326    Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "939753d861a24d1ea86474df0056ce0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b6731de6dac4ffeaf7474b2d80c2c48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48a4957ccc784baeb914d900053100d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer.fit(model=task, datamodule=datamodule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b8aa34f3-29e8-4900-8bad-73feec67aab0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: WARNING Source type is set to 'repo' but some required information is missing from the environment. A job will not be created from this run. See https://docs.wandb.ai/guides/launch/create-job\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4bf976283a144d7bcf119055d1c119f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='397.746 MB of 397.754 MB uploaded\\r'), FloatProgress(value=0.9999804567533667, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▃▅▆█</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▃▃▃▃▅▅▅▅▆▆▆▆█</td></tr><tr><td>val_MulticlassAccuracy</td><td>▁▁▁▁▁</td></tr><tr><td>val_MulticlassJaccardIndex</td><td>▁▁▁▁▁</td></tr><tr><td>val_loss</td><td>▄▁▂▆█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>4</td></tr><tr><td>trainer/global_step</td><td>39</td></tr><tr><td>val_MulticlassAccuracy</td><td>0.99325</td></tr><tr><td>val_MulticlassJaccardIndex</td><td>0.9866</td></tr><tr><td>val_loss</td><td>0.04573</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">0_losses+images</strong> at: <a href='https://wandb.ai/asm_detect/ASM_seg_test/runs/jz1ceomt' target=\"_blank\">https://wandb.ai/asm_detect/ASM_seg_test/runs/jz1ceomt</a><br/>Synced 6 W&B file(s), 66 media file(s), 5 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20231206_154837-jz1ceomt/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeaecbcb-dfdf-44f3-86bc-4e9ed825ba60",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:miniconda3-geo-ml]",
   "language": "python",
   "name": "conda-env-miniconda3-geo-ml-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
