{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "313ded3f-37d3-4e29-a657-e69276a24cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import multiprocessing as mp\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "import wandb\n",
    "import torch\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from segmentation_models_pytorch import Unet\n",
    "from collections import OrderedDict\n",
    "from torch.utils.data import DataLoader\n",
    "from lightning.pytorch import Trainer\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, auc\n",
    "\n",
    "sys.path.append(\"../scripts/\")\n",
    "from asm_datamodules import *\n",
    "from asm_models import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e055fe9c-366a-44ea-a706-6ee5b88bc30f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "346cc090-40ab-4043-9b5b-24307f8fe4d2",
   "metadata": {},
   "source": [
    "# Set up inference with lightning trainer functionalities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9bea4251-49b4-4f4f-a7e7-7267d0e99720",
   "metadata": {},
   "outputs": [],
   "source": [
    "#artifact_dir = \"/n/home07/kayan/asm/notebooks/artifacts/model-z1woyme2:v19\"\n",
    "artifact_dir = \"/n/home07/kayan/asm/notebooks/artifacts/model-ztyg139f:v19\"\n",
    "state_dict = torch.load(f\"{artifact_dir}/model.ckpt\")[\"state_dict\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "696de43a-cce8-4d0b-826c-2c68b7cbee03",
   "metadata": {},
   "outputs": [],
   "source": [
    "root = \"/n/holyscratch01/tambe_lab/kayan/karena/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e0c222c0-1e31-4571-9e32-28d9e0b2a32f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model parameters\n",
    "lr = 1e-5\n",
    "n_epoch = 5\n",
    "batch_size = 64\n",
    "loss = \"ce\"\n",
    "class_weights = [0.2,0.8]\n",
    "num_workers = 8\n",
    "mines_only = False\n",
    "split = False\n",
    "split_n = None\n",
    "split_path = \"/n/home07/kayan/asm/data/splits/9_all_data_lowlr_save-split\"\n",
    "freeze_backbone = False\n",
    "save_split = False\n",
    "\n",
    "task = CustomSemanticSegmentationTask(\n",
    "    model=\"unet\",\n",
    "    backbone=\"resnet18\",\n",
    "    weights=True,\n",
    "    loss=loss,\n",
    "    class_weights = torch.Tensor(class_weights),\n",
    "    in_channels=4,\n",
    "    num_classes=2,\n",
    "    lr=lr,\n",
    "    patience=5,\n",
    "    freeze_backbone=freeze_backbone,\n",
    "    freeze_decoder=False\n",
    ")\n",
    "\n",
    "task.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "91da38ec-e9e5-4c8a-a27c-63d593890a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# device configuration\n",
    "device, num_devices = (\"cuda\", torch.cuda.device_count()) if torch.cuda.is_available() else (\"cpu\", mp.cpu_count())\n",
    "workers = mp.cpu_count()\n",
    "torch.set_num_threads(32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a6809c0d-b6be-427c-9e26-1c990d753d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "datamodule = ASMDataModule(batch_size=batch_size, num_workers=num_workers, split=split, split_n=split_n, \n",
    "                           root=root, transforms=min_max_transform, mines_only=mines_only, split_path=split_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d3ebc1be-419a-409f-8e87-7c60fe1d9d66",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/n/home07/kayan/miniconda3/envs/geo-ml/lib/python3.11/site-packages/lightning/fabric/plugins/environments/slurm.py:191: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /n/home07/kayan/miniconda3/envs/geo-ml/lib/python3.1 ...\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "        accelerator=device,\n",
    "        devices=num_devices,\n",
    "        max_epochs=n_epoch,\n",
    "        logger=False,\n",
    "        enable_checkpointing=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d3a3192-a1e7-495b-a591-9e769bf76123",
   "metadata": {},
   "source": [
    "## Test by feeding in a datamodule, and print example input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0e023ff0-6f77-4864-b2e5-5e6f9d69b1a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [MIG-50048574-5e97-5636-860e-ec25631abc1b]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28fe3188c3ba4728a2fbcb38a9284094",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.1240, 0.1024, 0.0862,  ..., 0.4923, 0.5039, 0.5165],\n",
      "         [0.1132, 0.1496, 0.1420,  ..., 0.5943, 0.5915, 0.6119],\n",
      "         [0.1018, 0.1497, 0.1489,  ..., 0.6251, 0.6491, 0.6763],\n",
      "         ...,\n",
      "         [0.3329, 0.3062, 0.2777,  ..., 0.1909, 0.1932, 0.2264],\n",
      "         [0.3169, 0.3133, 0.2952,  ..., 0.2062, 0.2225, 0.2194],\n",
      "         [0.2521, 0.3097, 0.3133,  ..., 0.1845, 0.1942, 0.1942]],\n",
      "\n",
      "        [[0.1848, 0.1422, 0.1231,  ..., 0.5770, 0.5415, 0.5462],\n",
      "         [0.1800, 0.1972, 0.1851,  ..., 0.6386, 0.6058, 0.6290],\n",
      "         [0.1815, 0.2205, 0.2130,  ..., 0.6526, 0.6512, 0.6605],\n",
      "         ...,\n",
      "         [0.4474, 0.4141, 0.3756,  ..., 0.2359, 0.2133, 0.2211],\n",
      "         [0.4152, 0.4068, 0.3838,  ..., 0.2437, 0.2541, 0.2512],\n",
      "         [0.3560, 0.4033, 0.3997,  ..., 0.2258, 0.2702, 0.2962]],\n",
      "\n",
      "        [[0.1937, 0.1615, 0.1634,  ..., 0.5584, 0.5230, 0.4957],\n",
      "         [0.1788, 0.2158, 0.2240,  ..., 0.6307, 0.5971, 0.6347],\n",
      "         [0.1945, 0.2300, 0.2357,  ..., 0.6295, 0.6541, 0.7246],\n",
      "         ...,\n",
      "         [0.4794, 0.4059, 0.3191,  ..., 0.2667, 0.2733, 0.3101],\n",
      "         [0.4151, 0.3781, 0.3367,  ..., 0.2838, 0.2912, 0.2797],\n",
      "         [0.3134, 0.3779, 0.3964,  ..., 0.2708, 0.2474, 0.2251]],\n",
      "\n",
      "        [[0.2959, 0.2794, 0.2884,  ..., 0.4021, 0.3796, 0.3807],\n",
      "         [0.3519, 0.3408, 0.3464,  ..., 0.4149, 0.3914, 0.3930],\n",
      "         [0.4241, 0.4165, 0.4145,  ..., 0.4551, 0.4196, 0.4133],\n",
      "         ...,\n",
      "         [0.7639, 0.7428, 0.7261,  ..., 0.4393, 0.4674, 0.4849],\n",
      "         [0.7271, 0.7433, 0.7385,  ..., 0.4265, 0.4761, 0.5123],\n",
      "         [0.6847, 0.7306, 0.7256,  ..., 0.3945, 0.4494, 0.5104]]])\n",
      "Input data type: torch.float32\n",
      "Example input: tensor([[[0.0005, 0.0004, 0.0003,  ..., 0.0019, 0.0020, 0.0020],\n",
      "         [0.0004, 0.0006, 0.0006,  ..., 0.0023, 0.0023, 0.0024],\n",
      "         [0.0004, 0.0006, 0.0006,  ..., 0.0025, 0.0025, 0.0027],\n",
      "         ...,\n",
      "         [0.0013, 0.0012, 0.0011,  ..., 0.0007, 0.0008, 0.0009],\n",
      "         [0.0012, 0.0012, 0.0012,  ..., 0.0008, 0.0009, 0.0009],\n",
      "         [0.0010, 0.0012, 0.0012,  ..., 0.0007, 0.0008, 0.0008]],\n",
      "\n",
      "        [[0.0007, 0.0006, 0.0005,  ..., 0.0023, 0.0021, 0.0021],\n",
      "         [0.0007, 0.0008, 0.0007,  ..., 0.0025, 0.0024, 0.0025],\n",
      "         [0.0007, 0.0009, 0.0008,  ..., 0.0026, 0.0026, 0.0026],\n",
      "         ...,\n",
      "         [0.0018, 0.0016, 0.0015,  ..., 0.0009, 0.0008, 0.0009],\n",
      "         [0.0016, 0.0016, 0.0015,  ..., 0.0010, 0.0010, 0.0010],\n",
      "         [0.0014, 0.0016, 0.0016,  ..., 0.0009, 0.0011, 0.0012]],\n",
      "\n",
      "        [[0.0008, 0.0006, 0.0006,  ..., 0.0022, 0.0021, 0.0019],\n",
      "         [0.0007, 0.0008, 0.0009,  ..., 0.0025, 0.0023, 0.0025],\n",
      "         [0.0008, 0.0009, 0.0009,  ..., 0.0025, 0.0026, 0.0028],\n",
      "         ...,\n",
      "         [0.0019, 0.0016, 0.0013,  ..., 0.0010, 0.0011, 0.0012],\n",
      "         [0.0016, 0.0015, 0.0013,  ..., 0.0011, 0.0011, 0.0011],\n",
      "         [0.0012, 0.0015, 0.0016,  ..., 0.0011, 0.0010, 0.0009]],\n",
      "\n",
      "        [[0.0012, 0.0011, 0.0011,  ..., 0.0016, 0.0015, 0.0015],\n",
      "         [0.0014, 0.0013, 0.0014,  ..., 0.0016, 0.0015, 0.0015],\n",
      "         [0.0017, 0.0016, 0.0016,  ..., 0.0018, 0.0016, 0.0016],\n",
      "         ...,\n",
      "         [0.0030, 0.0029, 0.0028,  ..., 0.0017, 0.0018, 0.0019],\n",
      "         [0.0029, 0.0029, 0.0029,  ..., 0.0017, 0.0019, 0.0020],\n",
      "         [0.0027, 0.0029, 0.0028,  ..., 0.0015, 0.0018, 0.0020]]],\n",
      "       device='cuda:0')\n",
      "Sum of each channel: tensor([ 59.5528,  78.9694,  78.9013, 135.6229], device='cuda:0')\n",
      "Example output: tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0]], device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">         Test metric         </span>┃<span style=\"font-weight: bold\">        DataLoader 0         </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">   test_MulticlassAccuracy   </span>│<span style=\"color: #800080; text-decoration-color: #800080\">      0.990871012210846      </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\"> test_MulticlassJaccardIndex </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     0.9819071888923645      </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          test_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     0.10330305248498917     </span>│\n",
       "└─────────────────────────────┴─────────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m        Test metric        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m       DataLoader 0        \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m  test_MulticlassAccuracy  \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m     0.990871012210846     \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36mtest_MulticlassJaccardIndex\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9819071888923645     \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         test_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.10330305248498917    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└─────────────────────────────┴─────────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'test_loss': 0.10330305248498917,\n",
       "  'test_MulticlassAccuracy': 0.990871012210846,\n",
       "  'test_MulticlassJaccardIndex': 0.9819071888923645}]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.test(model=task, datamodule=datamodule)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5adf3584-2253-47b6-8ee8-0eb7576479c0",
   "metadata": {},
   "source": [
    "## Test by feeding in a DATALOADER, and print example input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c43d3e11-8cb8-41b9-9b91-603d4c3335e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataloader = datamodule._dataloader_factory(\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "75b5c918-ed02-44aa-b63c-03b9590f9a47",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [MIG-50048574-5e97-5636-860e-ec25631abc1b]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb4a551818604ddf81191109ff55bead",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input data type: torch.float32\n",
      "Example input: tensor([[[0.1240, 0.1024, 0.0862,  ..., 0.4923, 0.5039, 0.5165],\n",
      "         [0.1132, 0.1496, 0.1420,  ..., 0.5943, 0.5915, 0.6119],\n",
      "         [0.1018, 0.1497, 0.1489,  ..., 0.6251, 0.6491, 0.6763],\n",
      "         ...,\n",
      "         [0.3329, 0.3062, 0.2777,  ..., 0.1909, 0.1932, 0.2264],\n",
      "         [0.3169, 0.3133, 0.2952,  ..., 0.2062, 0.2225, 0.2194],\n",
      "         [0.2521, 0.3097, 0.3133,  ..., 0.1845, 0.1942, 0.1942]],\n",
      "\n",
      "        [[0.1848, 0.1422, 0.1231,  ..., 0.5770, 0.5415, 0.5462],\n",
      "         [0.1800, 0.1972, 0.1851,  ..., 0.6386, 0.6058, 0.6290],\n",
      "         [0.1815, 0.2205, 0.2130,  ..., 0.6526, 0.6512, 0.6605],\n",
      "         ...,\n",
      "         [0.4474, 0.4141, 0.3756,  ..., 0.2359, 0.2133, 0.2211],\n",
      "         [0.4152, 0.4068, 0.3838,  ..., 0.2437, 0.2541, 0.2512],\n",
      "         [0.3560, 0.4033, 0.3997,  ..., 0.2258, 0.2702, 0.2962]],\n",
      "\n",
      "        [[0.1937, 0.1615, 0.1634,  ..., 0.5584, 0.5230, 0.4957],\n",
      "         [0.1788, 0.2158, 0.2240,  ..., 0.6307, 0.5971, 0.6347],\n",
      "         [0.1945, 0.2300, 0.2357,  ..., 0.6295, 0.6541, 0.7246],\n",
      "         ...,\n",
      "         [0.4794, 0.4059, 0.3191,  ..., 0.2667, 0.2733, 0.3101],\n",
      "         [0.4151, 0.3781, 0.3367,  ..., 0.2838, 0.2912, 0.2797],\n",
      "         [0.3134, 0.3779, 0.3964,  ..., 0.2708, 0.2474, 0.2251]],\n",
      "\n",
      "        [[0.2959, 0.2794, 0.2884,  ..., 0.4021, 0.3796, 0.3807],\n",
      "         [0.3519, 0.3408, 0.3464,  ..., 0.4149, 0.3914, 0.3930],\n",
      "         [0.4241, 0.4165, 0.4145,  ..., 0.4551, 0.4196, 0.4133],\n",
      "         ...,\n",
      "         [0.7639, 0.7428, 0.7261,  ..., 0.4393, 0.4674, 0.4849],\n",
      "         [0.7271, 0.7433, 0.7385,  ..., 0.4265, 0.4761, 0.5123],\n",
      "         [0.6847, 0.7306, 0.7256,  ..., 0.3945, 0.4494, 0.5104]]],\n",
      "       device='cuda:0')\n",
      "Sum of each channel: tensor([15185.9697, 20137.1836, 20119.8223, 34583.8359], device='cuda:0')\n",
      "Example output: tensor([[0, 1, 1,  ..., 0, 0, 1],\n",
      "        [0, 1, 1,  ..., 0, 0, 0],\n",
      "        [0, 1, 1,  ..., 1, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0]], device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">         Test metric         </span>┃<span style=\"font-weight: bold\">        DataLoader 0         </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">   test_MulticlassAccuracy   </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     0.16873769462108612     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\"> test_MulticlassJaccardIndex </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     0.09214282780885696     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          test_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">      22.92302894592285      </span>│\n",
       "└─────────────────────────────┴─────────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m        Test metric        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m       DataLoader 0        \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m  test_MulticlassAccuracy  \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.16873769462108612    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36mtest_MulticlassJaccardIndex\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.09214282780885696    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         test_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m     22.92302894592285     \u001b[0m\u001b[35m \u001b[0m│\n",
       "└─────────────────────────────┴─────────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'test_loss': 22.92302894592285,\n",
       "  'test_MulticlassAccuracy': 0.16873769462108612,\n",
       "  'test_MulticlassJaccardIndex': 0.09214282780885696}]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.test(model=task, dataloaders=test_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "559b0039-644a-40ce-8ff5-b9dabb422dc1",
   "metadata": {},
   "source": [
    "Somewhere in the weeds of how the Trainer processes a datamodule vs dataloader, input data from the datamodule gets divided by 255 while input data from the dataloader doesn't.\n",
    "\n",
    "This model was trained by feeding in a datamodule -- so batch norm stats correspond to input data that has been divided by 255 (on top of min-max scaling). When we test on data from a dataloader, which only has min-max scaling, the stats are off which explains the terrible results. It also explains why running a few forward passes with model.train() before testing fixes the issue, since the batch norm stats adjust to the new data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2312e4d9-8b45-4f59-9340-2449ff05889f",
   "metadata": {},
   "source": [
    "# Confirm this is the root of the issue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05a39cb2-f6d9-4dfa-97d5-1b4bb334ef24",
   "metadata": {},
   "source": [
    "Let's try dividing data from the dataloader by 255, doing nothing else, and feeding it into test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "53693778-3002-44ed-abde-48551eb8c29f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_transform(sample):\n",
    "    ''''Does the same thing as min_max_transform, but performs additional division by 255'''\n",
    "    sample = min_max_transform(sample)\n",
    "    sample[\"image\"] = sample[\"image\"]/255\n",
    "    return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "494e1e80-9a89-45d1-a463-52db9e05ec81",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = ASMDataset(\n",
    "        root = \"/n/holyscratch01/tambe_lab/kayan/karena/\",\n",
    "        transforms = custom_transform,\n",
    "        split = \"test\",\n",
    "        bands = [\"R\", \"G\", \"B\", \"NIR\"],\n",
    "        split_path = split_path)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=64, num_workers=8, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "845fad2c-14ff-42d1-b717-3d5dce9e1881",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a CUDA device ('NVIDIA A100-SXM4-40GB MIG 3g.20gb') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [MIG-50048574-5e97-5636-860e-ec25631abc1b]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57feef185be74810b20a6d50dac193ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input data type: torch.float32\n",
      "Example input: tensor([[[0.0005, 0.0004, 0.0003,  ..., 0.0019, 0.0020, 0.0020],\n",
      "         [0.0004, 0.0006, 0.0006,  ..., 0.0023, 0.0023, 0.0024],\n",
      "         [0.0004, 0.0006, 0.0006,  ..., 0.0025, 0.0025, 0.0027],\n",
      "         ...,\n",
      "         [0.0013, 0.0012, 0.0011,  ..., 0.0007, 0.0008, 0.0009],\n",
      "         [0.0012, 0.0012, 0.0012,  ..., 0.0008, 0.0009, 0.0009],\n",
      "         [0.0010, 0.0012, 0.0012,  ..., 0.0007, 0.0008, 0.0008]],\n",
      "\n",
      "        [[0.0007, 0.0006, 0.0005,  ..., 0.0023, 0.0021, 0.0021],\n",
      "         [0.0007, 0.0008, 0.0007,  ..., 0.0025, 0.0024, 0.0025],\n",
      "         [0.0007, 0.0009, 0.0008,  ..., 0.0026, 0.0026, 0.0026],\n",
      "         ...,\n",
      "         [0.0018, 0.0016, 0.0015,  ..., 0.0009, 0.0008, 0.0009],\n",
      "         [0.0016, 0.0016, 0.0015,  ..., 0.0010, 0.0010, 0.0010],\n",
      "         [0.0014, 0.0016, 0.0016,  ..., 0.0009, 0.0011, 0.0012]],\n",
      "\n",
      "        [[0.0008, 0.0006, 0.0006,  ..., 0.0022, 0.0021, 0.0019],\n",
      "         [0.0007, 0.0008, 0.0009,  ..., 0.0025, 0.0023, 0.0025],\n",
      "         [0.0008, 0.0009, 0.0009,  ..., 0.0025, 0.0026, 0.0028],\n",
      "         ...,\n",
      "         [0.0019, 0.0016, 0.0013,  ..., 0.0010, 0.0011, 0.0012],\n",
      "         [0.0016, 0.0015, 0.0013,  ..., 0.0011, 0.0011, 0.0011],\n",
      "         [0.0012, 0.0015, 0.0016,  ..., 0.0011, 0.0010, 0.0009]],\n",
      "\n",
      "        [[0.0012, 0.0011, 0.0011,  ..., 0.0016, 0.0015, 0.0015],\n",
      "         [0.0014, 0.0013, 0.0014,  ..., 0.0016, 0.0015, 0.0015],\n",
      "         [0.0017, 0.0016, 0.0016,  ..., 0.0018, 0.0016, 0.0016],\n",
      "         ...,\n",
      "         [0.0030, 0.0029, 0.0028,  ..., 0.0017, 0.0018, 0.0019],\n",
      "         [0.0029, 0.0029, 0.0029,  ..., 0.0017, 0.0019, 0.0020],\n",
      "         [0.0027, 0.0029, 0.0028,  ..., 0.0015, 0.0018, 0.0020]]],\n",
      "       device='cuda:0')\n",
      "Sum of each channel: tensor([ 59.5528,  78.9694,  78.9013, 135.6229], device='cuda:0')\n",
      "Example output: tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0]], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/n/home07/kayan/miniconda3/envs/geo-ml/lib/python3.11/site-packages/lightning/pytorch/utilities/data.py:77: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 64. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "/n/home07/kayan/miniconda3/envs/geo-ml/lib/python3.11/site-packages/lightning/pytorch/utilities/data.py:77: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 39. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">         Test metric         </span>┃<span style=\"font-weight: bold\">        DataLoader 0         </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">   test_MulticlassAccuracy   </span>│<span style=\"color: #800080; text-decoration-color: #800080\">      0.990871012210846      </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\"> test_MulticlassJaccardIndex </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     0.9819071888923645      </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          test_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     0.10330305248498917     </span>│\n",
       "└─────────────────────────────┴─────────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m        Test metric        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m       DataLoader 0        \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m  test_MulticlassAccuracy  \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m     0.990871012210846     \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36mtest_MulticlassJaccardIndex\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9819071888923645     \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         test_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.10330305248498917    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└─────────────────────────────┴─────────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'test_loss': 0.10330305248498917,\n",
       "  'test_MulticlassAccuracy': 0.990871012210846,\n",
       "  'test_MulticlassJaccardIndex': 0.9819071888923645}]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.test(model=task, dataloaders=test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2e9622b-61ad-4d64-92df-da5e8ec776e7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:miniconda3-geo-ml]",
   "language": "python",
   "name": "conda-env-miniconda3-geo-ml-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
